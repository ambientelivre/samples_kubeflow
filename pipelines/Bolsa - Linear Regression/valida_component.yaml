name: Valida
inputs:
- {name: feat, type: String}
- {name: label, type: String}
- {name: dataset, type: String}
- {name: model}
outputs:
- {name: Output, type: 'typing.Dict[str, float]'}
implementation:
  container:
    image: tensorflow/tensorflow:1.11.0-py3
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def valida(feat, label, dataset, model_path):\n\n    import pickle\n    import\
      \ pandas as pd\n    from sklearn.metrics import mean_squared_error, r2_score,\
      \ mean_absolute_error\n\n    # Importando o dataset\n    df = pd.read_csv(dataset)\n\
      \    y_true = df[label]\n\n    # Importando o modelo serializado como um objeto\
      \ python\n    with open(model_path, 'rb') as f:\n        trained_model = pickle.load(f)\n\
      \n    y_pred = trained_model.predict(df[[feat]])\n\n    # Calcula as m\xE9tricas\
      \ de desempenho do modelo para o problema de regress\xE3o\n    r2 = r2_score(y_true,\
      \ y_pred)\n    mse = mean_squared_error(y_true, y_pred)\n    mae = mean_absolute_error(y_true,\
      \ y_pred)\n\n    valida_metrics = {\n        'r2' : r2,\n        'mse' : mse,\n\
      \        'mae' : mae\n    }\n\n    # Retorna um dicion\xE1rio com o c\xE1lculo\
      \ das m\xE9tricas\n\n    return valida_metrics\n\ndef _serialize_json(obj) ->\
      \ str:\n    if isinstance(obj, str):\n        return obj\n    import json\n\n\
      \    def default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n \
      \           return obj.to_struct()\n        else:\n            raise TypeError(\n\
      \                \"Object of type '%s' is not JSON serializable and does not\
      \ have .to_struct() method.\"\n                % obj.__class__.__name__)\n\n\
      \    return json.dumps(obj, default=default_serializer, sort_keys=True)\n\n\
      import argparse\n_parser = argparse.ArgumentParser(prog='Valida', description='')\n\
      _parser.add_argument(\"--feat\", dest=\"feat\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--label\", dest=\"label\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--dataset\", dest=\"dataset\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\", dest=\"model_path\"\
      , type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      ----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args\
      \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
      , [])\n\n_outputs = valida(**_parsed_args)\n\n_outputs = [_outputs]\n\n_output_serializers\
      \ = [\n    _serialize_json,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --feat
    - {inputValue: feat}
    - --label
    - {inputValue: label}
    - --dataset
    - {inputValue: dataset}
    - --model
    - {inputPath: model}
    - '----output-paths'
    - {outputPath: Output}
