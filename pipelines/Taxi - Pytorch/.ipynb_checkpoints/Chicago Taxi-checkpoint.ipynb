{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4f1d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.compiler as cpl\n",
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from kfp.components import create_component_from_func, InputPath, OutputPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa19c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_taxi_dataset_op = components.load_component('chicago_data_component.yaml')\n",
    "pandas_transform_csv_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/6162d55998b176b50267d351241100bb0ee715bc/components/pandas/Transform_DataFrame/in_CSV_format/component.yaml')\n",
    "download_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/240543e483076ae718f82c6f280441daa2f041fd/components/web/Download/component.yaml')\n",
    "create_fully_connected_pytorch_network_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/4e1facea1a270535b515a9e8cc59422d1ad76a9e/components/PyTorch/Create_fully_connected_network/component.yaml')\n",
    "convert_to_onnx_from_pytorch_script_module_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/e011e4affa85542ef2b24d63fdac27f8d939bbee/components/PyTorch/Convert_to_OnnxModel_from_PyTorchScriptModule/component.yaml')\n",
    "create_pytorch_model_archive_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/abc180be2b2b5538d19eb87124684629ec45e620/components/PyTorch/Create_PyTorch_Model_Archive/component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a602abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pytorch_model_from_csv(\n",
    "    model_path: InputPath('PyTorchScriptModule'),\n",
    "    training_data_path: InputPath('CSV'),\n",
    "    trained_model_path: OutputPath('PyTorchScriptModule'),\n",
    "    label_column_name: str,\n",
    "    loss_function_name: str = 'mse_loss',\n",
    "    number_of_epochs: int = 1,\n",
    "    learning_rate: float = 0.1,\n",
    "    optimizer_name: str = 'Adadelta',\n",
    "    optimizer_parameters: dict = None,\n",
    "    batch_size: int = 32,\n",
    "    batch_log_interval: int = 100,\n",
    "    random_seed: int = 0,\n",
    "):\n",
    "    '''Trains PyTorch model'''\n",
    "    import pandas\n",
    "    import torch\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    model = torch.jit.load(model_path)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer_class = getattr(torch.optim, optimizer_name, None)\n",
    "    if not optimizer_class:\n",
    "        raise ValueError(f'Optimizer \"{optimizer_name}\" was not found.')\n",
    "\n",
    "    optimizer_parameters = optimizer_parameters or {}\n",
    "    optimizer_parameters['lr'] = learning_rate\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_parameters)\n",
    "\n",
    "    loss_function = getattr(torch, loss_function_name, None) or getattr(torch.nn, loss_function_name, None) or getattr(torch.nn.functional, loss_function_name, None)\n",
    "    if not loss_function:\n",
    "        raise ValueError(f'Loss function \"{loss_function_name}\" was not found.')\n",
    "\n",
    "    class CsvDataset(torch.utils.data.Dataset):\n",
    "\n",
    "        def __init__(self, file_path: str, label_column_name: str, drop_nan_clumns_or_rows: str = 'columns'):\n",
    "            dataframe = pandas.read_csv(file_path)\n",
    "            # Preventing error: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object\n",
    "            if drop_nan_clumns_or_rows == 'columns':\n",
    "                non_nan_data = dataframe.dropna(axis='columns')\n",
    "                removed_columns = set(dataframe.columns) - set(non_nan_data.columns)\n",
    "                if removed_columns:\n",
    "                    print('Skipping columns with NaNs: ' + str(removed_columns))\n",
    "                dataframe = non_nan_data\n",
    "            if drop_nan_clumns_or_rows == 'rows':\n",
    "                non_nan_data = dataframe.dropna(axis='index')\n",
    "                number_of_removed_rows = len(dataframe) - len(non_nan_data)\n",
    "                if number_of_removed_rows:\n",
    "                    print(f'Skipped {number_of_removed_rows} rows with NaNs.')\n",
    "                dataframe = non_nan_data\n",
    "            numerical_data = dataframe.select_dtypes(include='number')\n",
    "            non_numerical_data = dataframe.select_dtypes(exclude='number')\n",
    "            if not non_numerical_data.empty:\n",
    "                print('Skipping non-number columns:')\n",
    "                print(non_numerical_data.dtypes)\n",
    "            self._dataframe = dataframe\n",
    "            self.labels = numerical_data[[label_column_name]]\n",
    "            self.features = numerical_data.drop(columns=[label_column_name])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self._dataframe)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return [self.features.loc[index].to_numpy(dtype='float32'), self.labels.loc[index].to_numpy(dtype='float32')]\n",
    "\n",
    "    dataset = CsvDataset(\n",
    "        file_path=training_data_path,\n",
    "        label_column_name=label_column_name,\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    last_full_batch_loss = None\n",
    "    for epoch in range(1, number_of_epochs + 1):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if len(data) == batch_size:\n",
    "                last_full_batch_loss = loss.item()\n",
    "            if batch_idx % batch_log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "        print(f'Training epoch {epoch} completed. Last full batch loss: {last_full_batch_loss:.6f}')\n",
    "\n",
    "    # print(optimizer.state_dict())\n",
    "    model.save(trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e49b13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch_model_from_csv_op = create_component_from_func(\n",
    "    train_pytorch_model_from_csv,\n",
    "    output_component_file='train_pytorch_model_from_csv_component.yaml',\n",
    "    base_image='pytorch/pytorch:1.7.1-cuda11.0-cudnn8-runtime',\n",
    "    packages_to_install=['pandas==1.1.5']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7c4111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch_model_from_csv_op = components.load_component('train_pytorch_model_from_csv_component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6aa207ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='Pipeline Chicago Taxi',\n",
    "    description='Exemplo Pytorch Chicago Taxi'\n",
    ")\n",
    "def pytorch_pipeline():\n",
    "    \n",
    "    # ExcluÃ­do \"trip_total\" para evitar vazamento de dados\n",
    "    feature_columns = ['trip_seconds', 'trip_miles', 'pickup_community_area', 'dropoff_community_area', 'fare', 'tolls', 'extras'] \n",
    "    label_column = 'tips'\n",
    "    \n",
    "    network = create_fully_connected_pytorch_network_op(\n",
    "        layer_sizes=[len(feature_columns), 100, 10, 1],\n",
    "        activation_name='elu',\n",
    "    ).output\n",
    "\n",
    "    training_data = chicago_taxi_dataset_op(\n",
    "        where='trip_start_timestamp >= \"2019-01-01\" AND trip_start_timestamp < \"2019-02-01\"',\n",
    "        select=','.join([label_column] + feature_columns),\n",
    "        limit=10000,\n",
    "    ).output\n",
    "\n",
    "    training_data = pandas_transform_csv_op(\n",
    "        table=training_data,\n",
    "        transform_code='''df = df.fillna({'tolls': 0.0, 'extras': 0.0}); \n",
    "                          df = df.dropna(axis='index')''',\n",
    "    ).output\n",
    "\n",
    "    trained_model = train_pytorch_model_from_csv_op(\n",
    "        model=network,\n",
    "        training_data=training_data,\n",
    "        label_column_name=label_column,\n",
    "        loss_function_name='mse_loss',\n",
    "        # Optional:\n",
    "        batch_size=32,\n",
    "        number_of_epochs=2,\n",
    "        random_seed=0,\n",
    "        learning_rate=0.1,\n",
    "        optimizer_name='Adadelta',\n",
    "        optimizer_parameters={},\n",
    "    ).outputs['trained_model']\n",
    "\n",
    "    convert_to_onnx_from_pytorch_script_module_op(\n",
    "        model=trained_model,\n",
    "        list_of_input_shapes=[[len(feature_columns)]],\n",
    "    )\n",
    "\n",
    "    # TODO: Use a real working regression handler here. See https://github.com/pytorch/serve/issues/987\n",
    "    serving_handler = download_op('https://raw.githubusercontent.com/pytorch/serve/5c03e711a401387a1d42fc01072fcc38b4995b66/ts/torch_handler/base_handler.py').output\n",
    "    \n",
    "    model_archive = create_pytorch_model_archive_op(\n",
    "        model=trained_model,\n",
    "        handler=serving_handler,\n",
    "        # model_name=\"model\",  # Optional\n",
    "        # model_version=\"1.0\",  # Optional\n",
    "    ).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "\n",
    "KFP_ENDPOINT='http://localhost:8080/pipeline'\n",
    "client = kfp.Client(host=KFP_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d60b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_run_from_pipeline_func(\n",
    "    pytorch_pipeline,\n",
    "    arguments={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6130de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl.Compiler().compile(\n",
    "    pipeline_func=pytorch_pipeline,\n",
    "    package_path='taxi_pytorch_pipeline.yaml'\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82b9d689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/pipeline/#/experiments/details/46e29c0a-18ee-4f8b-bee2-c413e627b904\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/pipeline/#/runs/details/5aae479f-2da9-4e2a-ac5b-a5749dd536de\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=5aae479f-2da9-4e2a-ac5b-a5749dd536de)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_run_from_pipeline_package(\n",
    "    pipeline_file='taxi_pytorch_pipeline.yaml',\n",
    "    arguments=args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe550d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
